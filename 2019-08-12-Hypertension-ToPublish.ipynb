{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code for Publication \"Improving Hypertension Case Identification Using Natural Language Processing and Machine Learning on Free-Text Electronic Medical Records\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, KFold\n",
    "from sklearn import tree\n",
    "import graphviz \n",
    "import xgboost as xgb\n",
    "\n",
    "import re\n",
    "import datetime\n",
    "import pickle\n",
    "import xml.etree.ElementTree as ET\n",
    "from os import listdir\n",
    "from itertools import islice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process documents with cTAKES and parse output "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process Documents with cTAKES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Specifications to pass to cTAKES\n",
    "\n",
    "#Your UMLS credentials\n",
    "username = \"***Your UMLS Username***\"\n",
    "password = \"***Your UMLS Password***\"\n",
    "\n",
    "#Path to cTAKES clinical pipeline ***REPLACE WITH YOUR PATH***\n",
    "pipeline = \"~/Resources/apache-ctakes-4.0.0/bin/runClinicalPipeline.sh\"\n",
    "\n",
    "#Folder containing the documents you want processed, to simplify linkage I used the chart number (RHRN) \n",
    "#as the document name: RHRN.txt\n",
    "inFolder = \" -i data/Text/DocType\"\n",
    "\n",
    "#Folder to put the annotated documents in\n",
    "outFolder = \" --xmiOut data/cTAKESoutput/DocType\"\n",
    "\n",
    "#UMLS credentials\n",
    "UMLScred = f\" --user {username} --pass {password}!\"\n",
    "\n",
    "#Final Shell command to execute\n",
    "cmd = pipeline + inFolder + outFolder + UMLScred\n",
    "\n",
    "!$cmd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse cTAKES output \n",
    "\n",
    "- create a dataframe where each row is a document\n",
    "- each column a CUI\n",
    "- each element is the number of times a given CUI appeared in the document, non-negated and referring to the patient\n",
    "\n",
    "This is then compiled into a new dataframe where each row is a patient, and each column is the sum over all documents of that type for that patient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "floc = \"data/DischargeSummaries/cTAKESoutput/DocType\"\n",
    "cDocs = listdir(floc)\n",
    "boc = pd.DataFrame()\n",
    "\n",
    "for count, doc in enumerate(cDocs):\n",
    "    tree = ET.parse(floc + doc) \n",
    "    root = tree.getroot()\n",
    "        \n",
    "    RHRN = doc.split('.')[0]\n",
    "    \n",
    "#     boc.loc[count] = 0\n",
    "#     boc['RHRN'].loc[count] =RHRN\n",
    "    \n",
    "    concepts = root.findall(\".//*[@ontologyConceptArr]\")\n",
    "    concepts = [x.attrib for x in concepts]\n",
    "    concepts = pd.DataFrame(concepts)\n",
    "    concepts = concepts[(concepts['subject'] == 'patient') & (concepts['polarity'] == '1')& (concepts['uncertainty']=='0')]\n",
    "    \n",
    "    cuis = root.findall(\".//*[@cui]\")\n",
    "    tmp = {'RHRN':RHRN}\n",
    "    for cui in cuis:\n",
    "        concept_id = cui.attrib['{http://www.omg.org/XMI}id']\n",
    "        if (concepts['ontologyConceptArr'].str.contains(concept_id).sum()) > 0:\n",
    "            ind = cui.attrib['cui']\n",
    "            try:\n",
    "                tmp[ind]+=1\n",
    "            except:\n",
    "                tmp[ind] = 1\n",
    "            \n",
    "        \n",
    "    boc = boc.append(tmp,ignore_index=True)\n",
    "    \n",
    "    if (count % 50)==0:\n",
    "        print(count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge cTAKES labels with DAD and Chart Review data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge output with DAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dad = pd.read_csv('data/DAD.csv',low_memory=False)\n",
    "dad['RHRN'] = dad['RHRN'].astype(str)\n",
    "boc = boc.merge(dad,on='RHRN')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge with Chart review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cr = pd.read_excel('data/ChartRev.xlsx',sheet_name='FULLDATA')\n",
    "boc = boc.merge(cr,on='RHRN')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove uncertain hypertension cases "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boc =boc.loc[boc['Hypertension present'] != 'Maybe']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modify labels so 1 = Hypertension present and 0 = Hypertension not present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boc['Hypertension present'] = (boc['Hypertension present'] == 'Yes').astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define some helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#always round .5 up\n",
    "import decimal\n",
    "context = decimal.getcontext()\n",
    "context.rounding = decimal.ROUND_HALF_UP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_out(func):\n",
    "    def standard_round(*args):\n",
    "        out = [int(round(decimal.Decimal(x*100), 0)) for x in func(*args)]\n",
    "        return f\"{out[0]}({out[0]-out[1]}-{out[0]+out[1]})\"\n",
    "    return standard_round\n",
    "\n",
    "@format_out\n",
    "def precision(predicted,actual):\n",
    "    predicted = np.array(predicted)\n",
    "    actual = np.array(actual)\n",
    "    p = sum(np.where(predicted & actual,1,0))/sum(predicted)\n",
    "    return p, ci(p,sum(predicted))\n",
    "\n",
    "@format_out\n",
    "def recall(predicted,actual):\n",
    "    predicted = np.array(predicted)\n",
    "    actual = np.array(actual)\n",
    "    r = sum(np.where(predicted & actual,1,0))/sum(actual)\n",
    "    return r, ci(r,sum(actual))\n",
    "\n",
    "@format_out\n",
    "def accuracy(predicted,actual):\n",
    "    predicted = np.array(predicted)\n",
    "    actual = np.array(actual)\n",
    "    a = sum(np.where(predicted==actual,1,0))/len(actual)\n",
    "    return a, ci(a,len(actual))\n",
    "\n",
    "@format_out\n",
    "def specificity(predicted,actual):\n",
    "    predicted = np.array(predicted)\n",
    "    predicted = 1 - predicted\n",
    "    actual = np.array(actual)\n",
    "    actual = 1 - actual\n",
    "    s = sum(np.where(predicted & actual,1,0))/sum(actual)\n",
    "    return s, ci(s,sum(actual))\n",
    "\n",
    "@format_out\n",
    "def NPV(predicted,actual):\n",
    "    predicted = np.array(predicted)\n",
    "    predicted = 1 - predicted\n",
    "    actual = np.array(actual)\n",
    "    actual = 1 - actual\n",
    "    n = sum(np.where(predicted & actual,1,0))/sum(predicted)\n",
    "    return n, ci(n,sum(predicted))\n",
    "\n",
    "# 95% confidence intervals\n",
    "def ci(p,N):\n",
    "    return 1.96*(p*(1-p)/N)**0.5\n",
    "\n",
    "\n",
    "def stats(predicted,actual):\n",
    "    print(\"Sample Size = \", len(actual))\n",
    "    print(\"Positive Cases = \",sum(actual))\n",
    "    print(\"Cases Labeled Positive = \", sum(predicted))\n",
    "#     print(\"Negative Cases = \", sum(1-actual))\n",
    "#     print(\"Cases Labeled Negative = \", sum(1-predicted))    \n",
    "    \n",
    "    print(\"Recall = \",recall(predicted,actual))\n",
    "    print(\"Specificity = \",specificity(predicted,actual))    \n",
    "    print(\"Precision = \",precision(predicted,actual))\n",
    "    print(\"NPV = \",NPV(predicted,actual))    \n",
    "    print(\"Accuracy = \",accuracy(predicted,actual))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create an ICD-10 case defintion column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select out all columns with ICD diagnoses codes\n",
    "cols = boc.columns\n",
    "codes = cols[cols.str.contains('dxcode',flags=re.IGNORECASE)]\n",
    "\n",
    "# Create a column containing all diagnoes codes concatenated together\n",
    "boc['AllCodes']=boc[codes].fillna(\"\").apply(lambda row: \" \".join([str(x) for x in row]),axis=1)\n",
    "\n",
    "# Create a column that equal 1 if it satisfies the ICD-10 hypertension definition and 0 otherwise\n",
    "boc['ICD Hypt'] = (boc['AllCodes'].str.contains('I10|I11|I12|I13|I15')).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature selection with XGBoost\n",
    "\n",
    "- This process is applied first on all Document types separately, and then using the top features from each model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select all CUIs as predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuis = boc.columns.str.contains('^C\\d')\n",
    "\n",
    "X = boc.loc[:,cuis]\n",
    "Y = boc['Hypertension present']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specify parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model = xgb.XGBClassifier()\n",
    "\n",
    "parameters = {'nthread':[32], #when use hyperthread, xgboost may become slower\n",
    "              'lambda':[0,0.5,1,2], #L2 regularization term on weights\n",
    "              'alpha':[0,0.5,1,2], #L1 regularization term on weights \n",
    "              'objective':['binary:logistic'],\n",
    "              'learning_rate': [0.05], #so called `eta` value\n",
    "              'max_depth': [3,5,6],\n",
    "              'min_child_weight': [4,8,16],\n",
    "              'silent': [1],\n",
    "              'subsample': [0.8],\n",
    "              'colsample_bytree': [0.7],\n",
    "              'n_estimators': [10,100,500,1000], #number of trees, change it to 1000 for better results\n",
    "              'seed': [42]}\n",
    "\n",
    "scoring = 'roc_auc'\n",
    "kf = KFold(n_splits=5,shuffle=True,random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Cross-Validated XGBoost models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fold, indices in enumerate(kf.split(X)):\n",
    "    \n",
    "    clf = GridSearchCV(xgb_model, parameters, n_jobs=6,\n",
    "                       cv=5, \n",
    "                       scoring=scoring,\n",
    "                       verbose=2, refit=True)\n",
    "\n",
    "    X_train = X.iloc[indices[0]]\n",
    "    Y_train = Y.iloc[indices[0]]\n",
    "    clf.fit(X_train, Y_train)\n",
    "    filename = f\"models/Hypt-Model-FOLD-{fold}-CaseIdent-XGBoost-AllCUIs-SubjNegUncer.pkl\"\n",
    "    pickle.dump(clf, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get stats for all folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = 5\n",
    "kf = KFold(n_splits=folds,shuffle=True,random_state=42)\n",
    "kf.get_n_splits(X)\n",
    "rec = []\n",
    "prec = []\n",
    "for i in range(folds):\n",
    "    train_ind, test_ind = next(islice(kf.split(X),i,i+1))\n",
    "    X_samp = X.iloc[test_ind]\n",
    "    Y_samp = Y.iloc[test_ind]\n",
    "    \n",
    "    filename = f'models/Hypt-Model-FOLD-{i}-CaseIdent-XGBoost-AllCUIs-NoICD11-SubjNegUncer.pkl'\n",
    "    clf = pickle.load(open(filename, 'rb'))\n",
    "    print(f'Fold {i} ---------------')\n",
    "    pred = clf.predict(X_samp)\n",
    "    rec.append(float(recall(pred,Y_samp)[0:2]))\n",
    "    prec.append(float(precision(pred,Y_samp)[0:2]))\n",
    "    stats(pred,Y_samp)\n",
    "\n",
    "print('mean recall', sum(rec)/folds)\n",
    "print('mean precision', sum(prec)/folds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare feature importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = 5\n",
    "\n",
    "nf = 20\n",
    "\n",
    "tfs = {}\n",
    "\n",
    "for i in range(folds):\n",
    "    filename = f'models/Hypt-Model-FOLD-{i}-CaseIdent-XGBoost-AllCUIs-SubjNegUncer.pkl'\n",
    "    clf = pickle.load(open(filename, 'rb'))    \n",
    "    \n",
    "    tg = clf.best_estimator_.get_booster().get_score(importance_type= \"gain\")\n",
    "    tg = pd.Series(tg)\n",
    "    tg.sort_values(ascending=False,inplace=True)\n",
    "    top_features = tg.iloc[:nf]\n",
    "    # top_features\n",
    "\n",
    "    tfs[i] = set(tg.index[:nf])\n",
    "\n",
    "    pos = np.arange(top_features.shape[0])\n",
    "    plt.subplot(folds, 1, i+1)\n",
    "    plt.bar(pos,top_features)\n",
    "#     plt.xticks(pos,top_features.index,rotation=-45)\n",
    "    plt.ylabel(\"Feature Importance\")\n",
    "    plt.xlabel(\"Feature Rank\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select features that all appear in the top nf features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agree = {}\n",
    "for tf in tfs:\n",
    "    try:\n",
    "        agree = agree.intersection(tfs[tf])\n",
    "    except:\n",
    "        agree = tfs[tf]\n",
    "        \n",
    "agree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit Decision tree using selected features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select features to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the 4 features that appear in the top 10 features (by gain) of all 5 folds of the optimized XGBoost models\n",
    "X = boc[agree]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.fillna(value=0,inplace=True)\n",
    "Y = boc['Hypertension present']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specify parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'criterion':['gini','entropy'],\n",
    "              'max_depth':range(3,15),\n",
    "              'min_samples_leaf':[3,5,10,20],\n",
    "              'ccp_alpha':[0.004,0.005,0.01]\n",
    "             }\n",
    "\n",
    "scoring = 'roc_auc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec = []\n",
    "prec = []\n",
    "for fold, indices in enumerate(kf.split(X)):\n",
    "    \n",
    "    clf = GridSearchCV(tree.DecisionTreeClassifier(splitter = 'best',random_state=42), \n",
    "                   parameters, cv = 10, \n",
    "                   n_jobs=4, scoring=scoring)\n",
    "\n",
    "    X_train = X.iloc[indices[0]]\n",
    "    Y_train = Y.iloc[indices[0]]\n",
    "    clf.fit(X_train, Y_train)\n",
    "    filename = f\"models/Hypertension-Model-FOLD-{fold}-CaseIdent-CART-3CUIWhichSeparate-SubjNegUncer.pkl\"\n",
    "    pickle.dump(clf, open(filename, 'wb'))\n",
    "\n",
    "    \n",
    "    print(f'Fold {fold} ---------------')\n",
    "    X_test = X.iloc[indices[1]]\n",
    "    Y_test = Y.iloc[indices[1]]\n",
    "    pred = clf.predict(X_test)\n",
    "    rec.append(float(recall(pred,Y_test)[0:2]))\n",
    "    prec.append(float(precision(pred,Y_test)[0:2]))\n",
    "    stats(pred,Y_test)\n",
    "\n",
    "print(\"*****AVERAGES*****\")\n",
    "print('mean recall', sum(rec)/folds)\n",
    "print('mean precision', sum(prec)/folds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdl = clf.best_estimator_\n",
    "dot_data = tree.export_graphviz(mdl, feature_names=X.columns,out_file=None,filled=True, rounded = True)\n",
    "graph = graphviz.Source(dot_data)\n",
    "graph"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
