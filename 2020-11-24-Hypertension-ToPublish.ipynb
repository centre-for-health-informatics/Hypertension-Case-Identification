{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code for Publication \"Explainable Data-Driven Hypertension Identification Using Inpatient EMR Clinical Notes\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV, KFold\n",
    "from sklearn import tree\n",
    "import graphviz \n",
    "import xgboost as xgb\n",
    "\n",
    "import shap\n",
    "\n",
    "import re\n",
    "import datetime\n",
    "import pickle\n",
    "import xml.etree.ElementTree as ET\n",
    "from os import listdir\n",
    "from itertools import islice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process documents with cTAKES and parse output "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process Documents with cTAKES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Specifications to pass to cTAKES\n",
    "\n",
    "#Your UMLS credentials\n",
    "username = \"***Your UMLS Username***\"\n",
    "password = \"***Your UMLS Password***\"\n",
    "\n",
    "#Path to cTAKES clinical pipeline ***REPLACE WITH YOUR PATH***\n",
    "pipeline = \"~/Resources/apache-ctakes-4.0.0/bin/runClinicalPipeline.sh\"\n",
    "\n",
    "#Folder containing the documents you want processed, to simplify linkage I used the chart number (RHRN) \n",
    "#as the document name: RHRN.txt\n",
    "inFolder = \" -i data/Text/DocType\"\n",
    "\n",
    "#Folder to put the annotated documents in\n",
    "outFolder = \" --xmiOut data/cTAKESoutput/DocType\"\n",
    "\n",
    "#UMLS credentials\n",
    "UMLScred = f\" --user {username} --pass {password}!\"\n",
    "\n",
    "#Final Shell command to execute\n",
    "cmd = pipeline + inFolder + outFolder + UMLScred\n",
    "\n",
    "!$cmd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse cTAKES output \n",
    "\n",
    "- create a dataframe where each row is a document\n",
    "- each column is a CUI, except the first which is a patient identifier (RHRN)\n",
    "- each element (outside the first column) is the number of times a given CUI appeared in the document, non-negated and referring to the patient\n",
    "\n",
    "These are then compiled into a new dataframe where each row is a patient, and each column is a CUI or Document-CUI pair. Each element is the total number of times that CUI appeared in the first case, or total number of times that CUI appeared in that document type in the second case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "floc = \"data/DischargeSummaries/cTAKESoutput/DocType\"\n",
    "cDocs = listdir(floc)\n",
    "boc = pd.DataFrame()\n",
    "\n",
    "for count, doc in enumerate(cDocs):\n",
    "    tree = ET.parse(floc + doc) \n",
    "    root = tree.getroot()\n",
    "        \n",
    "    RHRN = doc.split('.')[0]\n",
    "    \n",
    "#     boc.loc[count] = 0\n",
    "#     boc['RHRN'].loc[count] =RHRN\n",
    "    \n",
    "    concepts = root.findall(\".//*[@ontologyConceptArr]\")\n",
    "    concepts = [x.attrib for x in concepts]\n",
    "    concepts = pd.DataFrame(concepts)\n",
    "    concepts = concepts[(concepts['subject'] == 'patient') & (concepts['polarity'] == '1')& (concepts['uncertainty']=='0')]\n",
    "    \n",
    "    cuis = root.findall(\".//*[@cui]\")\n",
    "    tmp = {'RHRN':RHRN}\n",
    "    for cui in cuis:\n",
    "        concept_id = cui.attrib['{http://www.omg.org/XMI}id']\n",
    "        if (concepts['ontologyConceptArr'].str.contains(concept_id).sum()) > 0:\n",
    "            ind = cui.attrib['cui']\n",
    "            try:\n",
    "                tmp[ind]+=1\n",
    "            except:\n",
    "                tmp[ind] = 1\n",
    "            \n",
    "        \n",
    "    boc = boc.append(tmp,ignore_index=True)\n",
    "    \n",
    "    if (count % 50)==0:\n",
    "        print(count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge cTAKES labels with DAD and Chart Review data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge output with DAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dad = pd.read_csv('data/DAD.csv',low_memory=False)\n",
    "dad['RHRN'] = dad['RHRN'].astype(str)\n",
    "boc = boc.merge(dad,on='RHRN')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge with Chart review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cr = pd.read_excel('data/ChartRev.xlsx',sheet_name='FULLDATA')\n",
    "boc = boc.merge(cr,on='RHRN')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove uncertain hypertension cases "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boc =boc.loc[boc['Hypertension present'] != 'Maybe']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modify labels so 1 = Hypertension present and 0 = Hypertension not present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boc['Hypertension present'] = (boc['Hypertension present'] == 'Yes').astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define some helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#always round .5 up\n",
    "import decimal\n",
    "context = decimal.getcontext()\n",
    "context.rounding = decimal.ROUND_HALF_UP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_out(func):\n",
    "    def standard_round(*args):\n",
    "        out = [int(round(decimal.Decimal(x*100), 0)) for x in func(*args)]\n",
    "        return f\"{out[0]}({out[0]-out[1]}-{out[0]+out[1]})\"\n",
    "    return standard_round\n",
    "\n",
    "@format_out\n",
    "def precision(predicted,actual):\n",
    "    predicted = np.array(predicted)\n",
    "    actual = np.array(actual)\n",
    "    p = sum(np.where(predicted & actual,1,0))/sum(predicted)\n",
    "    return p, ci(p,sum(predicted))\n",
    "\n",
    "@format_out\n",
    "def recall(predicted,actual):\n",
    "    predicted = np.array(predicted)\n",
    "    actual = np.array(actual)\n",
    "    r = sum(np.where(predicted & actual,1,0))/sum(actual)\n",
    "    return r, ci(r,sum(actual))\n",
    "\n",
    "@format_out\n",
    "def accuracy(predicted,actual):\n",
    "    predicted = np.array(predicted)\n",
    "    actual = np.array(actual)\n",
    "    a = sum(np.where(predicted==actual,1,0))/len(actual)\n",
    "    return a, ci(a,len(actual))\n",
    "\n",
    "@format_out\n",
    "def specificity(predicted,actual):\n",
    "    predicted = np.array(predicted)\n",
    "    predicted = 1 - predicted\n",
    "    actual = np.array(actual)\n",
    "    actual = 1 - actual\n",
    "    s = sum(np.where(predicted & actual,1,0))/sum(actual)\n",
    "    return s, ci(s,sum(actual))\n",
    "\n",
    "@format_out\n",
    "def NPV(predicted,actual):\n",
    "    predicted = np.array(predicted)\n",
    "    predicted = 1 - predicted\n",
    "    actual = np.array(actual)\n",
    "    actual = 1 - actual\n",
    "    n = sum(np.where(predicted & actual,1,0))/sum(predicted)\n",
    "    return n, ci(n,sum(predicted))\n",
    "\n",
    "# 95% confidence intervals\n",
    "def ci(p,N):\n",
    "    return 1.96*(p*(1-p)/N)**0.5\n",
    "\n",
    "\n",
    "def stats(predicted,actual):\n",
    "    print(\"Sample Size = \", len(actual))\n",
    "    print(\"Positive Cases = \",sum(actual))\n",
    "    print(\"Cases Labeled Positive = \", sum(predicted))\n",
    "#     print(\"Negative Cases = \", sum(1-actual))\n",
    "#     print(\"Cases Labeled Negative = \", sum(1-predicted))    \n",
    "    \n",
    "    print(\"Recall = \",recall(predicted,actual))\n",
    "    print(\"Specificity = \",specificity(predicted,actual))    \n",
    "    print(\"Precision = \",precision(predicted,actual))\n",
    "    print(\"NPV = \",NPV(predicted,actual))    \n",
    "    print(\"Accuracy = \",accuracy(predicted,actual))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create an ICD-10 case defintion column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select out all columns with ICD diagnoses codes\n",
    "cols = boc.columns\n",
    "codes = cols[cols.str.contains('dxcode',flags=re.IGNORECASE)]\n",
    "\n",
    "# Create a column containing all diagnoes codes concatenated together\n",
    "boc['AllCodes']=boc[codes].fillna(\"\").apply(lambda row: \" \".join([str(x) for x in row]),axis=1)\n",
    "\n",
    "# Create a column that equal 1 if it satisfies the ICD-10 hypertension definition and 0 otherwise\n",
    "boc['ICD Hypt'] = (boc['AllCodes'].str.contains('I10|I11|I12|I13|I15')).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature selection with XGBoost\n",
    "\n",
    "- This process is applied first on all Document types separately, and then using the top features from each model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select all CUIs as predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuis = boc.columns.str.contains('^C\\d')\n",
    "\n",
    "X = boc.loc[:,cuis]\n",
    "Y = boc['Hypertension present']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split off training and testing sets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.20, stratify=Y_all, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specify parameters\n",
    "\n",
    "- this was performed on a GPU cluster, and the tree_method and predictor should be changed to run on a cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model = xgb.XGBClassifier()\n",
    "\n",
    "parameters = {\n",
    "    'lambda':[0,0.5,1], #L2 regularization term on weights\n",
    "    'alpha':[0,0.5,1], #L1 regularization term on weights \n",
    "    'learning_rate': [0.05], #so called `eta` value\n",
    "    'objective':['binary:logistic'],\n",
    "    'max_depth': [5,8],\n",
    "    'min_child_weight': [4,8],\n",
    "    'subsample': [0.8],\n",
    "    'colsample_bytree': [0.7],\n",
    "    'n_estimators': [500,1000], #number of trees, change it to 1000 for better results\n",
    "    'seed': [42],\n",
    "    'tree_method': ['gpu_hist'], \n",
    "    \"predictor\":['gpu_predictor']\n",
    "}\n",
    "\n",
    "scoring = 'roc_auc'\n",
    "skf = StratifiedKFold(n_splits=5,shuffle=True,random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Cross-Validated XGBoost models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fold, indices in enumerate(skf.split(X_train,Y_train)):\n",
    "    \n",
    "    print('Starting fold:',fold)\n",
    "    \n",
    "    clf = GridSearchCV(xgb_model, parameters, \n",
    "                       cv=5, \n",
    "                       scoring=scoring,\n",
    "                       verbose=2, refit=True)\n",
    "\n",
    "    X_samp = X_train.iloc[indices[0]]\n",
    "    Y_samp = Y_train.iloc[indices[0],0]\n",
    "    eval_set = [(X_train.iloc[indices[1]], Y_train.iloc[indices[1],0])]\n",
    "    \n",
    "    clf.fit(X_samp, Y_samp,eval_set=eval_set, early_stopping_rounds=10)\n",
    "    filename = f\"../Models/Hypt-Model-FOLD-{fold}-CaseIdent-JustCUIs-XGBoost-AllCUIs-AllDocs-SubjNeg.pkl\"\n",
    "    pickle.dump(clf, open(filename, 'wb'))\n",
    "\n",
    "    print('Finished fold:',fold)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get stats for all folds and get top features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nf = 20\n",
    "top_intersect = set()\n",
    "for fold, indices in enumerate(skf.split(X_train,Y_train)):\n",
    "    print(f'Fold {fold} results', 42*'#')\n",
    "    try:\n",
    "        clf = pickle.load(open(f\"../Models/Hypt-Model-FOLD-{fold}-CaseIdent-JustCUIs-XGBoost-AllCUIs-AllDocs-SubjNeg.pkl\",'rb'))\n",
    "    except:\n",
    "        print(f'Fold {fold} did not finish',42*'@')\n",
    "        continue\n",
    "        \n",
    "    for i in range(2): \n",
    "        pred = clf.predict(X_train.iloc[indices[i]])\n",
    "        stats(pred,Y_train['hypertension_present'].iloc[indices[i]])\n",
    "        print(30*'*')\n",
    "        \n",
    "    tg = clf.best_estimator_.get_booster().get_score(importance_type= \"gain\")\n",
    "    tg = pd.Series(tg)\n",
    "    tg.sort_values(ascending=False,inplace=True)\n",
    "    top_features = tg.iloc[:nf].index        \n",
    "    \n",
    "    if fold == 0:\n",
    "        top_intersect = set(top_features)\n",
    "    else:\n",
    "        top_intersect= top_intersect.intersection(set(top_features)) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare feature importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = 5\n",
    "\n",
    "nf = 20\n",
    "\n",
    "tfs = {}\n",
    "\n",
    "for i in range(folds):\n",
    "    filename = f'models/Hypt-Model-FOLD-{i}-CaseIdent-XGBoost-AllCUIs-SubjNegUncer.pkl'\n",
    "    clf = pickle.load(open(filename, 'rb'))    \n",
    "    \n",
    "    tg = clf.best_estimator_.get_booster().get_score(importance_type= \"gain\")\n",
    "    tg = pd.Series(tg)\n",
    "    tg.sort_values(ascending=False,inplace=True)\n",
    "    top_features = tg.iloc[:nf]\n",
    "    # top_features\n",
    "\n",
    "    tfs[i] = set(tg.index[:nf])\n",
    "\n",
    "    pos = np.arange(top_features.shape[0])\n",
    "    plt.subplot(folds, 1, i+1)\n",
    "    plt.bar(pos,top_features)\n",
    "#     plt.xticks(pos,top_features.index,rotation=-45)\n",
    "    plt.ylabel(\"Feature Importance\")\n",
    "    plt.xlabel(\"Feature Rank\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examine SHAP Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.initjs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = clf.best_estimator_\n",
    "explainer = shap.TreeExplainer(model)\n",
    "\n",
    "vals = X_train\n",
    "shap_values = explainer.shap_values(vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values,vals)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
